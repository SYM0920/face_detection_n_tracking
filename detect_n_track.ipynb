{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T09:08:00.853584Z",
     "start_time": "2019-02-26T09:07:58.155031Z"
    }
   },
   "outputs": [],
   "source": [
    "import imutils\n",
    "import time\n",
    "import cv2\n",
    "import os\n",
    "import colorsys\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "from yolo.model import eval\n",
    "from yolo.utils import letterbox_image\n",
    "\n",
    "from collections import deque, defaultdict\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "\n",
    "from PIL import ImageDraw, Image\n",
    "from sklearn.utils.linear_assignment_ import linear_assignment\n",
    "\n",
    "from numpy import dot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T09:08:00.903951Z",
     "start_time": "2019-02-26T09:08:00.857441Z"
    }
   },
   "outputs": [],
   "source": [
    "def box_iou(a, b):\n",
    "    '''\n",
    "    Helper funciton to calculate the ratio between intersection and the union of\n",
    "    two boxes a and b\n",
    "    a[0], a[1], a[2], a[3] <-> left, top, right, bottom\n",
    "    '''\n",
    "    \n",
    "    w_intsec = np.maximum (0, (np.minimum(a[2], b[2]) - np.maximum(a[0], b[0])))\n",
    "    h_intsec = np.maximum (0, (np.minimum(a[3], b[3]) - np.maximum(a[1], b[1])))\n",
    "    s_intsec = w_intsec * h_intsec\n",
    "    s_a = (a[2] - a[0])*(a[3] - a[1])\n",
    "    s_b = (b[2] - b[0])*(b[3] - b[1])\n",
    "  \n",
    "    return float(s_intsec)/(s_a + s_b -s_intsec)\n",
    "\n",
    "def convert_to_pixel(box_yolo, img, crop_range):\n",
    "    '''\n",
    "    Helper function to convert (scaled) coordinates of a bounding box \n",
    "    to pixel coordinates. \n",
    "    \n",
    "    Example (0.89361443264143803, 0.4880486045564924, 0.23544462956491041, \n",
    "    0.36866588651069609)\n",
    "    \n",
    "    crop_range: specifies the part of image to be cropped\n",
    "    '''\n",
    "    \n",
    "    box = box_yolo\n",
    "    imgcv = img\n",
    "    [xmin, xmax] = crop_range[0]\n",
    "    [ymin, ymax] = crop_range[1]\n",
    "    h, w, _ = imgcv.shape\n",
    "    \n",
    "    # Calculate left, top, width, and height of the bounding box\n",
    "    left = int((box.x - box.w/2.)*(xmax - xmin) + xmin)\n",
    "    top = int((box.y - box.h/2.)*(ymax - ymin) + ymin)\n",
    "    \n",
    "    width = int(box.w*(xmax - xmin))\n",
    "    height = int(box.h*(ymax - ymin))\n",
    "    \n",
    "    # Deal with corner cases\n",
    "    if left  < 0    :  left = 0\n",
    "    if top   < 0    :   top = 0\n",
    "    \n",
    "    # Return the coordinates (in the unit of the pixels)\n",
    "  \n",
    "    box_pixel = np.array([left, top, width, height])\n",
    "    return box_pixel\n",
    "\n",
    "def ltwh_to_ltrb(bbox, img_dim = (960, 720)):\n",
    "    '''\n",
    "    Helper fucntion for converting bbox to bbox_cv2\n",
    "    bbox = [left, top, width, height]\n",
    "    bbox_cv2 = [left, top, right, bottom]\n",
    "    img_dim: dimension of the image, img_dim[0]<-> x\n",
    "    img_dim[1]<-> y\n",
    "    '''\n",
    "    left = np.maximum(0, bbox[0])\n",
    "    top = np.maximum(0, bbox[1])\n",
    "    right = np.minimum(img_dim[0], bbox[0] + bbox[2])\n",
    "    bottom = np.minimum(img_dim[1], bbox[1] + bbox[3])\n",
    "    \n",
    "    return (int(left), int(top), int(right), int(bottom))\n",
    "\n",
    "def ltrb_to_ltwh(bbox, img_dim = (960, 720)):\n",
    "    '''\n",
    "    Helper fucntion for converting bbox to bbox_cv2\n",
    "    bbox_cv2 = [left, top, right, bottom]\n",
    "    bbox = [left, top, width, height]\n",
    "    img_dim: dimension of the image, img_dim[0]<-> x\n",
    "    img_dim[1]<-> y\n",
    "    '''\n",
    "    left = np.maximum(0, bbox[0])\n",
    "    top = np.maximum(0, bbox[1])\n",
    "    width = np.minimum(img_dim[0], bbox[2] - bbox[0])\n",
    "    height = np.minimum(img_dim[1], bbox[3] - bbox[1])\n",
    "    \n",
    "    return (int(left), int(top), int(width), int(height))\n",
    "\n",
    "def tlbr_to_ltrb(bbox, img_dim = (960, 720)):\n",
    "\n",
    "    left = np.maximum(0, bbox[1])\n",
    "    top = np.maximum(0, bbox[0])\n",
    "    right = np.minimum(img_dim[0], bbox[3])\n",
    "    bottom = np.minimum(img_dim[1], bbox[2])\n",
    "    \n",
    "    return (int(left), int(top), int(right), int(bottom))\n",
    "\n",
    "def draw_box_label(img, bbox_cv2, box_color=(0, 255, 255), show_label=False):\n",
    "    '''\n",
    "    Helper funciton for drawing the bounding boxes and the labels\n",
    "    bbox_cv2 = [left, top, right, bottom]\n",
    "    '''\n",
    "    #box_color= (0, 255, 255)\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    font_size = 0.7\n",
    "    font_color = (0, 0, 0)\n",
    "    left, top, right, bottom = bbox_cv2[0], bbox_cv2[1], bbox_cv2[2], bbox_cv2[3]\n",
    "    \n",
    "    # Draw the bounding box\n",
    "    cv2.rectangle(img, (left, top), (right, bottom), box_color, 4)\n",
    "    \n",
    "    if show_label:\n",
    "        # Draw a filled box on top of the bounding box (as the background for the labels)\n",
    "        cv2.rectangle(img, (left-2, top-45), (right+2, top), box_color, -1, 1)\n",
    "        \n",
    "        # Output the labels that show the x and y coordinates of the bounding box center.\n",
    "        text_x= 'x='+str((left+right)/2)\n",
    "        cv2.putText(img,text_x,(left,top-25), font, font_size, font_color, 1, cv2.LINE_AA)\n",
    "        text_y= 'y='+str((top+bottom)/2)\n",
    "        cv2.putText(img,text_y,(left,top-5), font, font_size, font_color, 1, cv2.LINE_AA)\n",
    "    \n",
    "    return img    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T09:08:00.946875Z",
     "start_time": "2019-02-26T09:08:00.907383Z"
    }
   },
   "outputs": [],
   "source": [
    "class YOLO(object):\n",
    "    def __init__(self):\n",
    "#         self.args = args\n",
    "        self.model_path = 'model-weights/YOLO_Face.h5'#args.model\n",
    "        self.classes_path = 'cfg/face_classes.txt'#args.classes\n",
    "        self.anchors_path = 'cfg/yolo_anchors.txt'#args.anchors\n",
    "        self.class_names = self._get_class()\n",
    "        self.anchors = self._get_anchors()\n",
    "        self.sess = K.get_session()\n",
    "        self.boxes, self.scores, self.classes = self._generate()\n",
    "        self.model_image_size = (416, 416)#args.img_size\n",
    "\n",
    "    def _get_class(self):\n",
    "        classes_path = os.path.expanduser(self.classes_path)\n",
    "        with open(classes_path) as f:\n",
    "            class_names = f.readlines()\n",
    "        class_names = [c.strip() for c in class_names]\n",
    "        print(class_names)\n",
    "        return class_names\n",
    "\n",
    "    def _get_anchors(self):\n",
    "        anchors_path = os.path.expanduser(self.anchors_path)\n",
    "        with open(anchors_path) as f:\n",
    "            anchors = f.readline()\n",
    "        anchors = [float(x) for x in anchors.split(',')]\n",
    "        return np.array(anchors).reshape(-1, 2)\n",
    "\n",
    "    def _generate(self):\n",
    "        model_path = os.path.expanduser(self.model_path)\n",
    "        assert model_path.endswith(\n",
    "            '.h5'), 'Keras model or weights must be a .h5 file'\n",
    "\n",
    "        # Load model, or construct model and load weights\n",
    "        num_anchors = len(self.anchors)\n",
    "        num_classes = len(self.class_names)\n",
    "        try:\n",
    "            self.yolo_model = load_model(model_path, compile=False)\n",
    "        except:\n",
    "            # make sure model, anchors and classes match\n",
    "            self.yolo_model.load_weights(self.model_path)\n",
    "        else:\n",
    "            assert self.yolo_model.layers[-1].output_shape[-1] == \\\n",
    "                   num_anchors / len(self.yolo_model.output) * (\n",
    "                           num_classes + 5), \\\n",
    "                'Mismatch between model and given anchor and class sizes'\n",
    "\n",
    "        print(\n",
    "            '[i] ==> {} model, anchors, and classes loaded.'.format(model_path))\n",
    "\n",
    "        # Generate colors for drawing bounding boxes\n",
    "        hsv_tuples = [(x / len(self.class_names), 1., 1.)\n",
    "                      for x in range(len(self.class_names))]\n",
    "        self.colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
    "        self.colors = list(\n",
    "            map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)),\n",
    "                self.colors))\n",
    "\n",
    "        # Shuffle colors to decorrelate adjacent classes.\n",
    "        np.random.seed(102)\n",
    "        np.random.shuffle(self.colors)\n",
    "        np.random.seed(None)\n",
    "\n",
    "        # Generate output tensor targets for filtered bounding boxes.\n",
    "        self.input_image_shape = K.placeholder(shape=(2,))\n",
    "        boxes, scores, classes = eval(self.yolo_model.output, self.anchors,\n",
    "                                           len(self.class_names),\n",
    "                                           self.input_image_shape,\n",
    "                                           score_threshold=0.5,\n",
    "                                           iou_threshold=0.45)\n",
    "        return boxes, scores, classes\n",
    "\n",
    "    def detect_image(self, image):\n",
    "        start_time = time.time()\n",
    "\n",
    "        if self.model_image_size != (None, None):\n",
    "            assert self.model_image_size[\n",
    "                       0] % 32 == 0, 'Multiples of 32 required'\n",
    "            assert self.model_image_size[\n",
    "                       1] % 32 == 0, 'Multiples of 32 required'\n",
    "            boxed_image = letterbox_image(image, tuple(\n",
    "                reversed(self.model_image_size)))\n",
    "        else:\n",
    "            new_image_size = (image.width - (image.width % 32),\n",
    "                              image.height - (image.height % 32))\n",
    "            boxed_image = letterbox_image(image, new_image_size)\n",
    "        image_data = np.array(boxed_image, dtype='float32')\n",
    "\n",
    "        print(image_data.shape)\n",
    "        image_data /= 255.\n",
    "        # Add batch dimension\n",
    "        image_data = np.expand_dims(image_data, 0)\n",
    "\n",
    "        out_boxes, out_scores, out_classes = self.sess.run(\n",
    "            [self.boxes, self.scores, self.classes],\n",
    "            feed_dict={\n",
    "                self.yolo_model.input: image_data,\n",
    "                self.input_image_shape: [image.size[1], image.size[0]],\n",
    "                K.learning_phase(): 0\n",
    "            })\n",
    "\n",
    "        print('[i] ==> Found {} face(s) for this image'.format(len(out_boxes)))\n",
    "        thickness = (image.size[0] + image.size[1]) // 400\n",
    "\n",
    "        for i, c in reversed(list(enumerate(out_classes))):\n",
    "            predicted_class = self.class_names[c]\n",
    "            box = out_boxes[i]\n",
    "            score = out_scores[i]\n",
    "\n",
    "            text = '{} {:.2f}'.format(predicted_class, score)\n",
    "            draw = ImageDraw.Draw(image)\n",
    "\n",
    "            top, left, bottom, right = box\n",
    "            top = max(0, np.floor(top + 0.5).astype('int32'))\n",
    "            left = max(0, np.floor(left + 0.5).astype('int32'))\n",
    "            bottom = min(image.size[1], np.floor(bottom + 0.5).astype('int32'))\n",
    "            right = min(image.size[0], np.floor(right + 0.5).astype('int32'))\n",
    "\n",
    "            print(text, (left, top), (right, bottom))\n",
    "\n",
    "#             for thk in range(thickness):\n",
    "#                 draw.rectangle(\n",
    "#                     [left + thk, top + thk, right - thk, bottom - thk],\n",
    "#                     outline=(51, 178, 255))\n",
    "#             del draw\n",
    "\n",
    "        end_time = time.time()\n",
    "        print('[i] ==> Processing time: {:.2f}ms'.format((end_time -\n",
    "                                                          start_time) * 1000))\n",
    "        return image, list(map(tuple,out_boxes))\n",
    "\n",
    "    def close_session(self):\n",
    "        self.sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T09:08:00.964560Z",
     "start_time": "2019-02-26T09:08:00.950280Z"
    }
   },
   "outputs": [],
   "source": [
    "class Tracker(): # class for Kalman Filter-based tracker\n",
    "    def __init__(self):\n",
    "        # Initialize parametes for tracker (history)\n",
    "        self.id = 0  # tracker's id \n",
    "        self.box = (0,0,0,0) # list to store the coordinates for a bounding box \n",
    "        self.hits = 0 # number of detection matches\n",
    "        self.no_losses = 0 # number of unmatched tracks (track loss)\n",
    "        \n",
    "        self.tracker = cv2.TrackerCSRT_create()\n",
    "        self.is_init = False\n",
    "    \n",
    "    def update(self, frame):\n",
    "        a,b = self.tracker.update(frame)\n",
    "        return (a,b)\n",
    "    \n",
    "    def init(self, image, box):\n",
    "        self.tracker.init(image, box)\n",
    "        self.is_init = True\n",
    "    \n",
    "    def release(self):\n",
    "#         self.tracker.release()\n",
    "        self.tracker.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T09:08:00.986674Z",
     "start_time": "2019-02-26T09:08:00.968633Z"
    }
   },
   "outputs": [],
   "source": [
    "def assign_detections_to_trackers(trackers, detections, iou_thrd = 0.3):\n",
    "    '''\n",
    "    From current list of trackers and new detections, output matched detections,\n",
    "    unmatchted trackers, unmatched detections.\n",
    "    '''    \n",
    "    \n",
    "    IOU_mat= np.zeros((len(trackers),len(detections)),dtype=np.float32)\n",
    "    for t,trk in enumerate(trackers):\n",
    "        for d,det in enumerate(detections):\n",
    "            IOU_mat[t,d] = box_iou(trk,det) \n",
    "    \n",
    "    # Produces matches       \n",
    "    # Solve the maximizing the sum of IOU assignment problem using the\n",
    "    # Hungarian algorithm (also known as Munkres algorithm)\n",
    "    \n",
    "    matched_idx = linear_assignment(-IOU_mat)        \n",
    "\n",
    "    unmatched_trackers, unmatched_detections = [], []\n",
    "    \n",
    "    for t,trk in enumerate(trackers):\n",
    "        if(t not in matched_idx[:,0]):\n",
    "            unmatched_trackers.append(t)\n",
    "\n",
    "    for d, det in enumerate(detections):\n",
    "        if(d not in matched_idx[:,1]):\n",
    "            unmatched_detections.append(d)\n",
    "\n",
    "    matches = []\n",
    "   \n",
    "    # For creating trackers we consider any detection with an \n",
    "    # overlap less than iou_thrd to signifiy the existence of \n",
    "    # an untracked object\n",
    "    \n",
    "    for m in matched_idx:\n",
    "        if(IOU_mat[m[0],m[1]]<iou_thrd):\n",
    "            unmatched_trackers.append(m[0])\n",
    "            unmatched_detections.append(m[1])\n",
    "        else:\n",
    "            matches.append(m.reshape(1,2))\n",
    "    \n",
    "    if(len(matches)==0):\n",
    "        matches = np.empty((0,2),dtype=int)\n",
    "    else:\n",
    "        matches = np.concatenate(matches,axis=0)\n",
    "    \n",
    "    return matches, unmatched_detections, unmatched_trackers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T09:08:01.024625Z",
     "start_time": "2019-02-26T09:08:00.989934Z"
    }
   },
   "outputs": [],
   "source": [
    "def pipeline(img):\n",
    "    '''\n",
    "    Pipeline function for detection and tracking\n",
    "    '''\n",
    "    global tracker_list\n",
    "    global track_id_list\n",
    "    global model\n",
    "    global people_count\n",
    "    global frame_count\n",
    "    global num_trackers\n",
    "     \n",
    "    if (frame_count%10==0):\n",
    "        \n",
    "        _, d_box = model.detect_image(img)\n",
    "\n",
    "        d_box = list(map(tlbr_to_ltrb, d_box))\n",
    "        \n",
    "        img = np.asarray(img)\n",
    "\n",
    "        img_dim = (img.shape[1], img.shape[0])\n",
    "\n",
    "        t_box =[]\n",
    "\n",
    "        if len(tracker_list) > 0:\n",
    "            for trk in tracker_list:\n",
    "                (_, xx) = trk.update(img)\n",
    "                xx = ltwh_to_ltrb(xx)\n",
    "                trk.box = xx\n",
    "                t_box.append(trk.box)\n",
    "\n",
    "        matched, unmatched_dets, unmatched_trks \\\n",
    "        = assign_detections_to_trackers(t_box, d_box, iou_thrd = 0.3)  \n",
    "\n",
    "        unmatched_trks.sort(reverse = True) \n",
    "\n",
    "        print('Detection: ', d_box)\n",
    "        print('t_box: ', t_box)\n",
    "        print('matched:', matched)\n",
    "        print('unmatched_det:', unmatched_dets)\n",
    "        print('unmatched_trks:', unmatched_trks)\n",
    "        print('people count:', people_count)\n",
    "        print('frame count:', frame_count)\n",
    "\n",
    "        # Deal with matched detections     \n",
    "        if matched.size > 0:\n",
    "            for trk_idx, det_idx in matched:\n",
    "                draw_box_label(img, tracker_list[trk_idx].box, box_color=(255, 0, 0))    \n",
    "\n",
    "        # Deal with unmatched detections      \n",
    "        if len(unmatched_dets)>0:\n",
    "            for idx in unmatched_dets:\n",
    "                z = d_box[idx]\n",
    "                tmp_trk = Tracker() # Create a new tracker\n",
    "                tmp_trk.init(img, ltrb_to_ltwh(z))\n",
    "                tmp_trk.box = z\n",
    "                if len(tracker_list)<num_trackers:\n",
    "                    tmp_trk.id = track_id_list.popleft() # assign an ID for the tracker\n",
    "                    tracker_list.append(tmp_trk)\n",
    "                else:\n",
    "                    del tmp_trk\n",
    "                draw_box_label(img, z, box_color=(0, 255, 0))\n",
    "\n",
    "        # Deal with unmatched tracks       \n",
    "        if len(unmatched_trks)>0:\n",
    "            for trk_idx in unmatched_trks:\n",
    "                draw_box_label(img, tracker_list[trk_idx].box, box_color=(0, 0, 255))\n",
    "                track_id_list.append(tracker_list[trk_idx].id)\n",
    "    #             tracker_list[trk_idx].release()\n",
    "                tracker_list.remove(tracker_list[trk_idx])\n",
    "                people_count+=1\n",
    "\n",
    "    else:\n",
    "        \n",
    "        img = np.asarray(img)\n",
    "\n",
    "        img_dim = (img.shape[1], img.shape[0])\n",
    "\n",
    "        t_box =[]\n",
    "        \n",
    "        if len(tracker_list) > 0:\n",
    "            for trk in tracker_list:\n",
    "                (success, xx) = trk.update(img)\n",
    "                if success:\n",
    "                    xx = ltwh_to_ltrb(xx)\n",
    "                    draw_box_label(img, xx, box_color=(0, 255, 255))\n",
    "                    trk.box = xx\n",
    "                    t_box.append(trk.box)\n",
    "        \n",
    "        print('t_box: ', t_box)\n",
    "        print('people count:', people_count)\n",
    "        print('frame count:', frame_count)\n",
    "        \n",
    "    print('Ending tracker_list: ',len(tracker_list))\n",
    "    frame_count+=1\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T09:08:15.633290Z",
     "start_time": "2019-02-26T09:08:01.027516Z"
    }
   },
   "outputs": [],
   "source": [
    "# Global variables to be used by funcitons of VideoFileClop\n",
    "frame_count = 0 # frame counter\n",
    "people_count = 0 #counting people\n",
    "\n",
    "tracker_list = [] # list for trackers\n",
    "track_id_list = deque(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J']) # list for track ID\n",
    "num_trackers = len(track_id_list)\n",
    "\n",
    "model = YOLO()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T09:08:15.703210Z",
     "start_time": "2019-02-26T09:08:15.635712Z"
    }
   },
   "outputs": [],
   "source": [
    "filename = 'pres.mp4'\n",
    "inputs = 'inputs/'\n",
    "vid = cv2.VideoCapture(os.path.join(inputs, filename))\n",
    "\n",
    "output = 'outputs/'\n",
    "output_fn = ('{}.avi'.format(filename))\n",
    "\n",
    "if not vid.isOpened():\n",
    "    raise IOError(\"Couldn't open video\")\n",
    "\n",
    "video_fourcc = cv2.VideoWriter_fourcc('M', 'J', 'P', 'G')\n",
    "\n",
    "video_fps = vid.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "video_size = (int(vid.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
    "              int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "\n",
    "isOutput = True if output != \"\" else False\n",
    "\n",
    "if isOutput:\n",
    "    out = cv2.VideoWriter(os.path.join(output, output_fn), video_fourcc, video_fps, video_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T09:09:33.532493Z",
     "start_time": "2019-02-26T09:08:15.706113Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    start = time.time()\n",
    "    ret, frame = vid.read()\n",
    "    if ret:\n",
    "        image = Image.fromarray(frame)\n",
    "\n",
    "        result = pipeline(image)\n",
    "\n",
    "        if isOutput:\n",
    "            print('Printing Out', time.time()-start)\n",
    "            print()\n",
    "            out.write(result)        \n",
    "    else:\n",
    "        break\n",
    "        \n",
    "vid.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
